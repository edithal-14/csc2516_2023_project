{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from utils import write_transform_to_file\n",
    "write_transform_to_file('credit') # needs to be run only once per dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data transformer and the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import itertools\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from ctgan.synthesizers.ae_gan import CTGANV2\n",
    "from benchmark import train_model\n",
    "from utils import load_transform_from_file, read_target_idx, sample_fake_credit\n",
    "\n",
    "\n",
    "AE_TYPES = ['vanilla', 'denoising', 'vae', 'ee']\n",
    "HP = {\n",
    "    'ae_dim' : [(256,128), (256,128,64), (256,128,64,32)], # (1)\n",
    "    'embedding_dim' : [64, 128, 256], #(2)\n",
    "    'gan_layers': [(256,256), (256,256,256,256)], # (3)\n",
    "    'discriminator_steps': [1, 5], # (4)\n",
    "    'pac': [4, 8, 16], # (4)\n",
    "    'gan_lr': [1e-5, 2e-4], # (5)\n",
    "    'gan_batch_epoch': [(256,150), (512,300)], # (5)\n",
    "    'ae_lr': [1e-4, 2e-4, 1e-3], # (5)\n",
    "    'ae_batch_epoch': [(256,50), (512,100)], # (5)\n",
    "}\n",
    "if os.path.exists(\"credit_opt_hp.json\"):\n",
    "    with open(\"credit_opt_hp.json\", 'r') as f:\n",
    "        hp_vals = json.load(f)\n",
    "else:\n",
    "    hp_vals = {k:dict.fromkeys(HP.keys()) for k in AE_TYPES}\n",
    "    for method in hp_vals.keys():\n",
    "        hp_vals[method]['dstep_pac'] = hp_vals[method].pop('discriminator_steps')\n",
    "        del hp_vals[method]['pac']\n",
    "        hp_vals[method]['gbe_aeb'] = hp_vals[method].pop('gan_lr')\n",
    "        del hp_vals[method]['gan_batch_epoch']\n",
    "        del hp_vals[method]['ae_lr']\n",
    "        del hp_vals[method]['ae_batch_epoch']\n",
    "\n",
    "# Load the transformed data\n",
    "dt, td = load_transform_from_file('credit')\n",
    "target_idx = read_target_idx('credit')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Find the optimal AE dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = 'ae_dim'\n",
    "\n",
    "for ae_type in AE_TYPES:\n",
    "    hp_scores = dict()\n",
    "    for v in HP[hp]:\n",
    "        k = '_'.join(str(i) for i in v)\n",
    "        if not os.path.exists(f\"../../models/ae_gan_{ae_type}_{hp}_{k}.pth\"):\n",
    "            # Train the AE_GAN\n",
    "            print(f\"Training CTGAN: {ae_type} - {hp} - {v}\")\n",
    "            ae_gan = CTGANV2(ae_type=ae_type, ae_dim=v)\n",
    "            ae_gan.fit(td['train'],dt=dt,is_transformed=True, target_index=target_idx)\n",
    "            print(\"Training Complete!\")\n",
    "            # save model\n",
    "            ae_gan.save(f\"../../models/ae_gan_{ae_type}_{hp}_{k}.pth\")\n",
    "        else:\n",
    "            print(f\"Loading CTGAN: {ae_type} - {hp} - {v}\")\n",
    "            ae_gan = CTGANV2().load(f\"../../models/ae_gan_{ae_type}_{hp}_{k}.pth\")\n",
    "\n",
    "        best_score = torch.tensor([0.0])\n",
    "        try:\n",
    "            # Sample fake data\n",
    "            fake_data, real_data = sample_fake_credit(dt,td,ae_gan)\n",
    "            \n",
    "            print(\"Benchmarking on MLP100\")\n",
    "            # Train the MLP on fake validation data\n",
    "            for _ in range(3):\n",
    "                test_score = train_model(\n",
    "                                fake_data[0],\n",
    "                                fake_data[1],\n",
    "                                fake_data[2],\n",
    "                                fake_data[3],\n",
    "                                real_data[0],\n",
    "                                real_data[1],\n",
    "                                batch_size=256,\n",
    "                                num_epochs=100,\n",
    "                                model_type=\"classification\",\n",
    "                                verbose=False,\n",
    "                                scorer_type=\"f1_minority\",\n",
    "                            )\n",
    "                if test_score > best_score:\n",
    "                    best_score = test_score\n",
    "            print(\"Benchmark Complete!\")\n",
    "        except:\n",
    "            pass\n",
    "        hp_scores[k] = best_score.item()\n",
    "    \n",
    "    hp_vals[ae_type][hp] = hp_scores\n",
    "    with open(\"credit_opt_hp.json\", 'w') as f:\n",
    "        f.write(json.dumps(hp_vals))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Find the optimal G latent dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = 'embedding_dim'\n",
    "\n",
    "for ae_type in AE_TYPES:\n",
    "    hp_scores = dict()\n",
    "    printable_ae_dim = max(hp_vals[ae_type]['ae_dim'].items(), key=lambda x: x[1])[0]\n",
    "    ae_dim = tuple(map(int, printable_ae_dim.split('_')))\n",
    "    for v in HP[hp]:\n",
    "        if not os.path.exists(f\"../../models/ae_gan_{ae_type}_ae_dim_{printable_ae_dim}_{hp}_{v}.pth\"):\n",
    "            # Train the AE_GAN\n",
    "            print(f\"Training CTGAN: {ae_type} - ae_dim - {printable_ae_dim} - {hp} - {v}\")\n",
    "            ae_gan = CTGANV2(ae_type=ae_type, ae_dim=ae_dim, embedding_dim=v)\n",
    "            ae_gan.fit(td['train'],dt=dt,is_transformed=True, target_index=target_idx)\n",
    "            print(\"Training Complete!\")\n",
    "            # save model\n",
    "            ae_gan.save(f\"../../models/ae_gan_{ae_type}_ae_dim_{printable_ae_dim}_{hp}_{v}.pth\")\n",
    "        else:\n",
    "            print(f\"Loading CTGAN: {ae_type} - ae_dim - {printable_ae_dim} - {hp} - {v}\")\n",
    "            ae_gan = CTGANV2().load(f\"../../models/ae_gan_{ae_type}_ae_dim_{printable_ae_dim}_{hp}_{v}.pth\")\n",
    "\n",
    "        best_score = torch.tensor([0.0])\n",
    "        try:\n",
    "            # Sample fake data\n",
    "            fake_data, real_data = sample_fake_credit(dt,td,ae_gan)\n",
    "            \n",
    "            print(\"Benchmarking on MLP100\")\n",
    "            # Train the MLP on fake validation data\n",
    "            for _ in range(3):\n",
    "                test_score = train_model(\n",
    "                                fake_data[0],\n",
    "                                fake_data[1],\n",
    "                                fake_data[2],\n",
    "                                fake_data[3],\n",
    "                                real_data[0],\n",
    "                                real_data[1],\n",
    "                                batch_size=256,\n",
    "                                num_epochs=100,\n",
    "                                model_type=\"classification\",\n",
    "                                verbose=False,\n",
    "                                scorer_type=\"f1_minority\",\n",
    "                            )\n",
    "                if test_score > best_score:\n",
    "                    best_score = test_score\n",
    "            print(\"Benchmark Complete!\")\n",
    "        except:\n",
    "            pass\n",
    "        hp_scores[v] = best_score.item()\n",
    "    \n",
    "    hp_vals[ae_type][hp] = hp_scores\n",
    "    with open(\"credit_opt_hp.json\", 'w') as f:\n",
    "        f.write(json.dumps(hp_vals))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Find the optimal no G/D layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = 'gan_layers'\n",
    "\n",
    "for ae_type in AE_TYPES:\n",
    "    hp_scores = dict()\n",
    "    printable_ae_dim = max(hp_vals[ae_type]['ae_dim'].items(), key=lambda x: x[1])[0]\n",
    "    ae_dim = tuple(map(int, printable_ae_dim.split('_')))\n",
    "    embedding_dim = int(max(hp_vals[ae_type]['embedding_dim'].items(), key=lambda x: x[1])[0])\n",
    "    for v in HP[hp]:\n",
    "        k = '_'.join(str(i) for i in v)\n",
    "        if not os.path.exists(f\"../../models/ae_gan_{ae_type}_ae_dim_{printable_ae_dim}_emb_{embedding_dim}_{hp}_{v}.pth\"):\n",
    "            # Train the AE_GAN\n",
    "            print(f\"Training CTGAN: {ae_type} - ae_dim - {printable_ae_dim} - embed_dim - {embedding_dim} - {hp} - {v}\")\n",
    "            ae_gan = CTGANV2(ae_type=ae_type, ae_dim=ae_dim,\n",
    "                             embedding_dim=embedding_dim, generator_dim=v, discriminator_dim=v)\n",
    "            ae_gan.fit(td['train'], dt=dt, is_transformed=True, target_index=target_idx)\n",
    "            print(\"Training Complete!\")\n",
    "            # save model\n",
    "            ae_gan.save(f\"../../models/ae_gan_{ae_type}_ae_dim_{printable_ae_dim}_emb_{embedding_dim}_{hp}_{v}.pth\")\n",
    "        else:\n",
    "            print(f\"Loading CTGAN: {ae_type} - ae_dim - {printable_ae_dim} - embed_dim - {embedding_dim} - {hp} - {v}\")\n",
    "            ae_gan = CTGANV2().load(f\"../../models/ae_gan_{ae_type}_ae_dim_{printable_ae_dim}_emb_{embedding_dim}_{hp}_{v}.pth\")\n",
    "\n",
    "        best_score = torch.tensor([0.0])\n",
    "        try:\n",
    "            # Sample fake data\n",
    "            fake_data, real_data = sample_fake_credit(dt,td,ae_gan)\n",
    "            \n",
    "            print(\"Benchmarking on MLP100\")\n",
    "            # Train the MLP on fake validation data\n",
    "            for _ in range(3):\n",
    "                test_score = train_model(\n",
    "                                fake_data[0],\n",
    "                                fake_data[1],\n",
    "                                fake_data[2],\n",
    "                                fake_data[3],\n",
    "                                real_data[0],\n",
    "                                real_data[1],\n",
    "                                batch_size=256,\n",
    "                                num_epochs=100,\n",
    "                                model_type=\"classification\",\n",
    "                                verbose=False,\n",
    "                                scorer_type=\"f1_minority\",\n",
    "                            )\n",
    "                if test_score > best_score:\n",
    "                    best_score = test_score\n",
    "            print(\"Benchmark Complete!\")\n",
    "        except:\n",
    "            pass\n",
    "        hp_scores[k] = best_score.item()\n",
    "    \n",
    "    hp_vals[ae_type][hp] = hp_scores\n",
    "    with open(\"credit_opt_hp.json\", 'w') as f:\n",
    "        f.write(json.dumps(hp_vals))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Find the optimal no D_steps and pac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = 'dstep_pac'\n",
    "dstep_pac = list(itertools.product(HP['discriminator_steps'], HP['pac']))\n",
    "\n",
    "for ae_type in AE_TYPES:\n",
    "    hp_scores = dict()\n",
    "    printable_ae_dim = max(hp_vals[ae_type]['ae_dim'].items(), key=lambda x: x[1])[0]\n",
    "    ae_dim = tuple(map(int, printable_ae_dim.split('_')))\n",
    "    embedding_dim = int(max(hp_vals[ae_type]['embedding_dim'].items(), key=lambda x: x[1])[0])\n",
    "    printable_gan_layers = max(hp_vals[ae_type]['gan_layers'].items(), key=lambda x: x[1])[0]\n",
    "    gan_layers = tuple(map(int, printable_gan_layers.split('_')))\n",
    "    for v1, v2 in dstep_pac:\n",
    "        k = '_'.join(map(str,[v1,v2]))\n",
    "        if not os.path.exists(f\"../../models/ae_gan_{ae_type}_ae_dim_{printable_ae_dim}_emb_{embedding_dim}_gla_{gan_layers}_dstep_{v1}_pac_{v2}.pth\"):\n",
    "            # Train the AE_GAN\n",
    "            print(f\"Training CTGAN: {ae_type} - ae_dim - {printable_ae_dim} - embed_dim - {embedding_dim} - gan_layers - {printable_gan_layers} - dstep - {v1} - pac - {v2}\")\n",
    "            ae_gan = CTGANV2(ae_type=ae_type, ae_dim=ae_dim, embedding_dim=embedding_dim,\n",
    "                                generator_dim=gan_layers, discriminator_dim=gan_layers,\n",
    "                                discriminator_steps=v1, pac=v2)\n",
    "            ae_gan.fit(td['train'], dt=dt, is_transformed=True, target_index=target_idx)\n",
    "            print(\"Training Complete!\")\n",
    "            # save model\n",
    "            ae_gan.save(f\"../../models/ae_gan_{ae_type}_ae_dim_{printable_ae_dim}_emb_{embedding_dim}_gla_{gan_layers}_dstep_{v1}_pac_{v2}.pth\")\n",
    "        else:\n",
    "            print(f\"Loading CTGAN: {ae_type} - ae_dim - {printable_ae_dim} - embed_dim - {embedding_dim} - gan_layers - {printable_gan_layers} - dstep - {v1} - pac - {v2}\")\n",
    "            ae_gan = CTGANV2().load(f\"../../models/ae_gan_{ae_type}_ae_dim_{printable_ae_dim}_emb_{embedding_dim}_gla_{gan_layers}_dstep_{v1}_pac_{v2}.pth\")\n",
    "\n",
    "        best_score = torch.tensor([0.0])\n",
    "        try:\n",
    "            # Sample fake data\n",
    "            fake_data, real_data = sample_fake_credit(dt,td,ae_gan)\n",
    "            \n",
    "            print(\"Benchmarking on MLP100\")\n",
    "            # Train the MLP on fake validation data\n",
    "            for _ in range(3):\n",
    "                test_score = train_model(\n",
    "                                fake_data[0],\n",
    "                                fake_data[1],\n",
    "                                fake_data[2],\n",
    "                                fake_data[3],\n",
    "                                real_data[0],\n",
    "                                real_data[1],\n",
    "                                batch_size=256,\n",
    "                                num_epochs=100,\n",
    "                                model_type=\"classification\",\n",
    "                                verbose=False,\n",
    "                                scorer_type=\"f1_minority\",\n",
    "                            )\n",
    "                if test_score > best_score:\n",
    "                    best_score = test_score\n",
    "            print(\"Benchmark Complete!\")\n",
    "        except:\n",
    "            pass\n",
    "        hp_scores[k] = best_score.item()\n",
    "    \n",
    "    hp_vals[ae_type][hp] = hp_scores\n",
    "    with open(\"credit_opt_hp.json\", 'w') as f:\n",
    "        f.write(json.dumps(hp_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) Find the optimal GAN LR, GAN BatchSize-Epoch, AE LR, AE BatchSize-Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "hp = 'gbe_aeb'\n",
    "gbe_aeb = list(itertools.product(HP['gan_lr'], HP['gan_batch_epoch'], HP['ae_lr'], HP['ae_batch_epoch']))\n",
    "gbe_aeb = [elem for elem in gbe_aeb if not ((elem[3] == (256, 50) and elem[1] == (512, 300)) or (elem[1] == (256, 150) and elem[3] == (512, 100)))]\n",
    "\n",
    "for ae_type in tqdm(AE_TYPES):\n",
    "    hp_scores = dict()\n",
    "    printable_ae_dim = max(hp_vals[ae_type]['ae_dim'].items(), key=lambda x: x[1])[0]\n",
    "    ae_dim = tuple(map(int, printable_ae_dim.split('_')))\n",
    "    embedding_dim = int(max(hp_vals[ae_type]['embedding_dim'].items(), key=lambda x: x[1])[0])\n",
    "    printable_gan_layers = max(hp_vals[ae_type]['gan_layers'].items(), key=lambda x: x[1])[0]\n",
    "    gan_layers = tuple(map(int, printable_gan_layers.split('_')))\n",
    "    d_step, pac = list(map(int,max(hp_vals[ae_type]['dstep_pac'].items(), key=lambda x: x[1])[0].split('_')))\n",
    "    for v1, v2, v3, v4 in tqdm(gbe_aeb):\n",
    "        pv2 = '_'.join(map(str,v2))\n",
    "        pv4 = '_'.join(map(str,v4))\n",
    "        k = '_'.join(map(str,[v1,pv2,v3,pv4]))\n",
    "        mpath = f\"../../models/ae_gan_{ae_type}_ae_dim_{printable_ae_dim}_emb_{embedding_dim}_gla_{gan_layers}_dstep_{d_step}_pac_{pac}_glr_{v1}_gbe_{pv2}_alr_{v3}_aeb_{pv4}.pth\"\n",
    "        if not os.path.exists(mpath):\n",
    "            # Train the AE_GAN\n",
    "            print(f\"Training CTGAN: {ae_type} - ae_dim - {printable_ae_dim} - embed_dim - {embedding_dim} - gan_layers - {printable_gan_layers} - dstep - {d_step} - pac - {pac} - gan_lr - {v1} - gan_batch_epoch - {pv2} - ae_lr - {v3} - ae_batch_epoch - {pv4}\")\n",
    "            ae_gan = CTGANV2(ae_type=ae_type, ae_dim=ae_dim, embedding_dim=embedding_dim,\n",
    "                                generator_dim=gan_layers, discriminator_dim=gan_layers,\n",
    "                                discriminator_steps=d_step, pac=pac, generator_lr=v1, discriminator_lr=v1,\n",
    "                                batch_size=v2[0], epochs=v2[1], autoencoder_lr=v3, ae_batch_size=v4[0], ae_epochs=v4[1])\n",
    "            ae_gan.fit(td['train'], dt=dt, is_transformed=True, target_index=target_idx)\n",
    "            print(\"Training Complete!\")\n",
    "            # save model\n",
    "            ae_gan.save(mpath)\n",
    "        else:\n",
    "            print(f\"Loading CTGAN: {ae_type} - ae_dim - {printable_ae_dim} - embed_dim - {embedding_dim} - gan_layers - {printable_gan_layers} - dstep - {d_step} - pac - {pac} - gan_lr - {v1} - gan_batch_epoch - {pv2} - ae_lr - {v3} - ae_batch_epoch - {pv4}\")\n",
    "            ae_gan = CTGANV2().load(mpath)\n",
    "\n",
    "        best_score = torch.tensor([0.0])\n",
    "        try:\n",
    "            # Sample fake data\n",
    "            fake_data, real_data = sample_fake_credit(dt,td,ae_gan)\n",
    "            \n",
    "            print(\"Benchmarking on MLP100\")\n",
    "            # Train the MLP on fake validation data\n",
    "            for _ in range(3):\n",
    "                test_score = train_model(\n",
    "                                fake_data[0],\n",
    "                                fake_data[1],\n",
    "                                fake_data[2],\n",
    "                                fake_data[3],\n",
    "                                real_data[0],\n",
    "                                real_data[1],\n",
    "                                batch_size=256,\n",
    "                                num_epochs=100,\n",
    "                                model_type=\"classification\",\n",
    "                                verbose=False,\n",
    "                                scorer_type=\"f1_minority\",\n",
    "                            )\n",
    "                if test_score > best_score:\n",
    "                    best_score = test_score\n",
    "            print(\"Benchmark Complete!\")\n",
    "        except:\n",
    "            pass\n",
    "        hp_scores[k] = best_score.item()\n",
    "    \n",
    "    hp_vals[ae_type][hp] = hp_scores\n",
    "    with open(\"credit_opt_hp.json\", 'w') as f:\n",
    "        f.write(json.dumps(hp_vals))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc2516",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
