{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from utils import write_transform_to_file\n",
    "write_transform_to_file('loan') # needs to be run only once per dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data transformer and the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformer loaded\n",
      "Transformed data loaded\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import itertools\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from ctgan.synthesizers.ae_gan import CTGANV2\n",
    "from benchmark import train_model\n",
    "from utils import load_transform_from_file, read_target_idx, sample_fake_loan\n",
    "\n",
    "\n",
    "AE_TYPES = ['vanilla', 'denoising', 'vae', 'ee']\n",
    "HP = {\n",
    "    'ae_dim' : [(256,128,64), (256,128,64,32)], # (1)\n",
    "    'embedding_dim' : [64, 128, 256], #(2)\n",
    "    'gan_layers': [(256,256), (256,256,256,256)], # (3)\n",
    "    'discriminator_steps': [1, 5], # (4)\n",
    "    'pac': [4, 8, 16], # (4)\n",
    "    'gan_lr': [1e-5, 2e-4], # (5)\n",
    "    'gan_batch_epoch': [(256,150), (512,300)], # (5)\n",
    "    'ae_lr': [1e-4, 2e-4, 1e-3], # (5)\n",
    "    'ae_batch_epoch': [(256,50), (512,100)], # (5)\n",
    "}\n",
    "if os.path.exists(\"loan_opt_hp.json\"):\n",
    "    with open(\"loan_opt_hp.json\", 'r') as f:\n",
    "        hp_vals = json.load(f)\n",
    "else:\n",
    "    hp_vals = {k:dict.fromkeys(HP.keys()) for k in AE_TYPES}\n",
    "    for method in hp_vals.keys():\n",
    "        hp_vals[method]['dstep_pac'] = hp_vals[method].pop('discriminator_steps')\n",
    "        del hp_vals[method]['pac']\n",
    "        hp_vals[method]['gbe_aeb'] = hp_vals[method].pop('gan_lr')\n",
    "        del hp_vals[method]['gan_batch_epoch']\n",
    "        del hp_vals[method]['ae_lr']\n",
    "        del hp_vals[method]['ae_batch_epoch']\n",
    "\n",
    "# Load the transformed data\n",
    "dt, td = load_transform_from_file('loan')\n",
    "target_idx = read_target_idx('loan')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Find the optimal AE dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTGAN: vanilla - ae_dim - (256, 128, 64)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d368df1edf0c41e38907d0cd476845ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AE Train:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ad9a5f348446b3ad65924bf4eb6347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Train:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining CTGAN: \u001b[39m\u001b[39m{\u001b[39;00mae_type\u001b[39m}\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m{\u001b[39;00mhp\u001b[39m}\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m{\u001b[39;00mv\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m ae_gan \u001b[39m=\u001b[39m CTGANV2(ae_type\u001b[39m=\u001b[39mae_type, ae_dim\u001b[39m=\u001b[39mv)\n\u001b[0;32m---> 11\u001b[0m ae_gan\u001b[39m.\u001b[39;49mfit(td[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m],dt\u001b[39m=\u001b[39;49mdt,is_transformed\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, target_index\u001b[39m=\u001b[39;49mtarget_idx)\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining Complete!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[39m# save model\u001b[39;00m\n",
      "File \u001b[0;32m~/CSC2516_Project/code/ctgan/ctgan/synthesizers/base.py:50\u001b[0m, in \u001b[0;36mrandom_state.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     49\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_states \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m         \u001b[39mreturn\u001b[39;00m function(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     52\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m         \u001b[39mwith\u001b[39;00m set_random_states(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_states, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_random_state):\n",
      "File \u001b[0;32m~/CSC2516_Project/code/ctgan/ctgan/synthesizers/ae_gan.py:565\u001b[0m, in \u001b[0;36mCTGANV2.fit\u001b[0;34m(self, train_data, discrete_columns, epochs, ae_epochs, target_index, dt, is_transformed)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[39m# discriminator backprop\u001b[39;00m\n\u001b[1;32m    564\u001b[0m optimizerD\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> 565\u001b[0m pen\u001b[39m.\u001b[39;49mbackward(retain_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    566\u001b[0m loss_d\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    567\u001b[0m optimizerD\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/csc2516/lib/python3.9/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/csc2516/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hp = 'ae_dim'\n",
    "\n",
    "for ae_type in AE_TYPES:\n",
    "    hp_scores = dict()\n",
    "    for v in HP[hp]:\n",
    "        k = '_'.join(str(i) for i in v)\n",
    "        if not os.path.exists(f\"../../models/tmp/loan/ae_gan_{ae_type}_{hp}_{k}.pth\"):\n",
    "            # Train the AE_GAN\n",
    "            print(f\"Training CTGAN: {ae_type} - {hp} - {v}\")\n",
    "            ae_gan = CTGANV2(ae_type=ae_type, ae_dim=v)\n",
    "            ae_gan.fit(td['train'],dt=dt,is_transformed=True, target_index=target_idx)\n",
    "            print(\"Training Complete!\")\n",
    "            # save model\n",
    "            ae_gan.save(f\"../../models/tmp/loan/ae_gan_{ae_type}_{hp}_{k}.pth\")\n",
    "        else:\n",
    "            print(f\"Loading CTGAN: {ae_type} - {hp} - {v}\")\n",
    "            ae_gan = CTGANV2().load(f\"../../models/tmp/loan/ae_gan_{ae_type}_{hp}_{k}.pth\")\n",
    "\n",
    "        best_score = torch.tensor([0.0])\n",
    "        try:\n",
    "            # Sample fake data\n",
    "            fake_data, real_data = sample_fake_loan(dt,td,ae_gan)\n",
    "            \n",
    "            print(\"Benchmarking on MLP100\")\n",
    "            # Train the MLP on fake validation data\n",
    "            for _ in range(3):\n",
    "                test_score = train_model(\n",
    "                                fake_data[0],\n",
    "                                fake_data[1],\n",
    "                                fake_data[2],\n",
    "                                fake_data[3],\n",
    "                                real_data[0],\n",
    "                                real_data[1],\n",
    "                                batch_size=256,\n",
    "                                num_epochs=100,\n",
    "                                model_type=\"classification\",\n",
    "                                verbose=False,\n",
    "                                scorer_type=\"f1_micro\",\n",
    "                            )\n",
    "                if test_score > best_score:\n",
    "                    best_score = test_score\n",
    "            print(\"Benchmark Complete!\")\n",
    "        except:\n",
    "            pass\n",
    "        hp_scores[k] = best_score.item()\n",
    "    \n",
    "    hp_vals[ae_type][hp] = hp_scores\n",
    "    with open(\"loan_opt_hp.json\", 'w') as f:\n",
    "        f.write(json.dumps(hp_vals))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Find the optimal G latent dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = 'embedding_dim'\n",
    "\n",
    "for ae_type in AE_TYPES:\n",
    "    hp_scores = dict()\n",
    "    printable_ae_dim = max(hp_vals[ae_type]['ae_dim'].items(), key=lambda x: x[1])[0]\n",
    "    ae_dim = tuple(map(int, printable_ae_dim.split('_')))\n",
    "    for v in HP[hp]:\n",
    "        if not os.path.exists(f\"../../models/ae_gan_{ae_type}_ae_dim_{printable_ae_dim}_{hp}_{v}.pth\"):\n",
    "            # Train the AE_GAN\n",
    "            print(f\"Training CTGAN: {ae_type} - ae_dim - {printable_ae_dim} - {hp} - {v}\")\n",
    "            ae_gan = CTGANV2(ae_type=ae_type, ae_dim=ae_dim, embedding_dim=v)\n",
    "            ae_gan.fit(td['train'],dt=dt,is_transformed=True, target_index=target_idx)\n",
    "            print(\"Training Complete!\")\n",
    "            # save model\n",
    "            ae_gan.save(f\"../../models/ae_gan_{ae_type}_ae_dim_{printable_ae_dim}_{hp}_{v}.pth\")\n",
    "        else:\n",
    "            print(f\"Loading CTGAN: {ae_type} - ae_dim - {printable_ae_dim} - {hp} - {v}\")\n",
    "            ae_gan = CTGANV2().load(f\"../../models/ae_gan_{ae_type}_ae_dim_{printable_ae_dim}_{hp}_{v}.pth\")\n",
    "\n",
    "        best_score = torch.tensor([0.0])\n",
    "        try:\n",
    "            # Sample fake data\n",
    "            fake_data, real_data = sample_fake_loan(dt,td,ae_gan)\n",
    "            \n",
    "            print(\"Benchmarking on MLP100\")\n",
    "            # Train the MLP on fake validation data\n",
    "            for _ in range(3):\n",
    "                test_score = train_model(\n",
    "                                fake_data[0],\n",
    "                                fake_data[1],\n",
    "                                fake_data[2],\n",
    "                                fake_data[3],\n",
    "                                real_data[0],\n",
    "                                real_data[1],\n",
    "                                batch_size=256,\n",
    "                                num_epochs=100,\n",
    "                                model_type=\"classification\",\n",
    "                                verbose=False,\n",
    "                                scorer_type=\"f1_micro\",\n",
    "                            )\n",
    "                if test_score > best_score:\n",
    "                    best_score = test_score\n",
    "            print(\"Benchmark Complete!\")\n",
    "        except:\n",
    "            pass\n",
    "        hp_scores[v] = best_score.item()\n",
    "    \n",
    "    hp_vals[ae_type][hp] = hp_scores\n",
    "    with open(\"loan_opt_hp.json\", 'w') as f:\n",
    "        f.write(json.dumps(hp_vals))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Find the optimal no G/D layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = 'gan_layers'\n",
    "\n",
    "for ae_type in AE_TYPES:\n",
    "    hp_scores = dict()\n",
    "    printable_ae_dim = max(hp_vals[ae_type]['ae_dim'].items(), key=lambda x: x[1])[0]\n",
    "    ae_dim = tuple(map(int, printable_ae_dim.split('_')))\n",
    "    embedding_dim = int(max(hp_vals[ae_type]['embedding_dim'].items(), key=lambda x: x[1])[0])\n",
    "    for v in HP[hp]:\n",
    "        k = '_'.join(str(i) for i in v)\n",
    "        if not os.path.exists(f\"../../models/ae_gan_{ae_type}_ae_dim_{printable_ae_dim}_emb_{embedding_dim}_{hp}_{v}.pth\"):\n",
    "            # Train the AE_GAN\n",
    "            print(f\"Training CTGAN: {ae_type} - ae_dim - {printable_ae_dim} - embed_dim - {embedding_dim} - {hp} - {v}\")\n",
    "            ae_gan = CTGANV2(ae_type=ae_type, ae_dim=ae_dim,\n",
    "                             embedding_dim=embedding_dim, generator_dim=v, discriminator_dim=v)\n",
    "            ae_gan.fit(td['train'], dt=dt, is_transformed=True, target_index=target_idx)\n",
    "            print(\"Training Complete!\")\n",
    "            # save model\n",
    "            ae_gan.save(f\"../../models/ae_gan_{ae_type}_ae_dim_{printable_ae_dim}_emb_{embedding_dim}_{hp}_{v}.pth\")\n",
    "        else:\n",
    "            print(f\"Loading CTGAN: {ae_type} - ae_dim - {printable_ae_dim} - embed_dim - {embedding_dim} - {hp} - {v}\")\n",
    "            ae_gan = CTGANV2().load(f\"../../models/ae_gan_{ae_type}_ae_dim_{printable_ae_dim}_emb_{embedding_dim}_{hp}_{v}.pth\")\n",
    "\n",
    "        best_score = torch.tensor([0.0])\n",
    "        try:\n",
    "            # Sample fake data\n",
    "            fake_data, real_data = sample_fake_loan(dt,td,ae_gan)\n",
    "            \n",
    "            print(\"Benchmarking on MLP100\")\n",
    "            # Train the MLP on fake validation data\n",
    "            for _ in range(3):\n",
    "                test_score = train_model(\n",
    "                                fake_data[0],\n",
    "                                fake_data[1],\n",
    "                                fake_data[2],\n",
    "                                fake_data[3],\n",
    "                                real_data[0],\n",
    "                                real_data[1],\n",
    "                                batch_size=256,\n",
    "                                num_epochs=100,\n",
    "                                model_type=\"classification\",\n",
    "                                verbose=False,\n",
    "                                scorer_type=\"f1_micro\",\n",
    "                            )\n",
    "                if test_score > best_score:\n",
    "                    best_score = test_score\n",
    "            print(\"Benchmark Complete!\")\n",
    "        except:\n",
    "            pass\n",
    "        hp_scores[k] = best_score.item()\n",
    "    \n",
    "    hp_vals[ae_type][hp] = hp_scores\n",
    "    with open(\"loan_opt_hp.json\", 'w') as f:\n",
    "        f.write(json.dumps(hp_vals))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Find the optimal no D_steps and pac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = 'dstep_pac'\n",
    "dstep_pac = list(itertools.product(HP['discriminator_steps'], HP['pac']))\n",
    "\n",
    "for ae_type in AE_TYPES:\n",
    "    hp_scores = dict()\n",
    "    printable_ae_dim = max(hp_vals[ae_type]['ae_dim'].items(), key=lambda x: x[1])[0]\n",
    "    ae_dim = tuple(map(int, printable_ae_dim.split('_')))\n",
    "    embedding_dim = int(max(hp_vals[ae_type]['embedding_dim'].items(), key=lambda x: x[1])[0])\n",
    "    printable_gan_layers = max(hp_vals[ae_type]['gan_layers'].items(), key=lambda x: x[1])[0]\n",
    "    gan_layers = tuple(map(int, printable_gan_layers.split('_')))\n",
    "    for v1, v2 in dstep_pac:\n",
    "        k = '_'.join(map(str,[v1,v2]))\n",
    "        if not os.path.exists(f\"../../models/ae_gan_{ae_type}_ae_dim_{printable_ae_dim}_emb_{embedding_dim}_gla_{gan_layers}_dstep_{v1}_pac_{v2}.pth\"):\n",
    "            # Train the AE_GAN\n",
    "            print(f\"Training CTGAN: {ae_type} - ae_dim - {printable_ae_dim} - embed_dim - {embedding_dim} - gan_layers - {printable_gan_layers} - dstep - {v1} - pac - {v2}\")\n",
    "            ae_gan = CTGANV2(ae_type=ae_type, ae_dim=ae_dim, embedding_dim=embedding_dim,\n",
    "                                generator_dim=gan_layers, discriminator_dim=gan_layers,\n",
    "                                discriminator_steps=v1, pac=v2)\n",
    "            ae_gan.fit(td['train'], dt=dt, is_transformed=True, target_index=target_idx)\n",
    "            print(\"Training Complete!\")\n",
    "            # save model\n",
    "            ae_gan.save(f\"../../models/ae_gan_{ae_type}_ae_dim_{printable_ae_dim}_emb_{embedding_dim}_gla_{gan_layers}_dstep_{v1}_pac_{v2}.pth\")\n",
    "        else:\n",
    "            print(f\"Loading CTGAN: {ae_type} - ae_dim - {printable_ae_dim} - embed_dim - {embedding_dim} - gan_layers - {printable_gan_layers} - dstep - {v1} - pac - {v2}\")\n",
    "            ae_gan = CTGANV2().load(f\"../../models/ae_gan_{ae_type}_ae_dim_{printable_ae_dim}_emb_{embedding_dim}_gla_{gan_layers}_dstep_{v1}_pac_{v2}.pth\")\n",
    "\n",
    "        best_score = torch.tensor([0.0])\n",
    "        try:\n",
    "            # Sample fake data\n",
    "            fake_data, real_data = sample_fake_loan(dt,td,ae_gan)\n",
    "            \n",
    "            print(\"Benchmarking on MLP100\")\n",
    "            # Train the MLP on fake validation data\n",
    "            for _ in range(3):\n",
    "                test_score = train_model(\n",
    "                                fake_data[0],\n",
    "                                fake_data[1],\n",
    "                                fake_data[2],\n",
    "                                fake_data[3],\n",
    "                                real_data[0],\n",
    "                                real_data[1],\n",
    "                                batch_size=256,\n",
    "                                num_epochs=100,\n",
    "                                model_type=\"classification\",\n",
    "                                verbose=False,\n",
    "                                scorer_type=\"f1_micro\",\n",
    "                            )\n",
    "                if test_score > best_score:\n",
    "                    best_score = test_score\n",
    "            print(\"Benchmark Complete!\")\n",
    "        except:\n",
    "            pass\n",
    "        hp_scores[k] = best_score.item()\n",
    "    \n",
    "    hp_vals[ae_type][hp] = hp_scores\n",
    "    with open(\"loan_opt_hp.json\", 'w') as f:\n",
    "        f.write(json.dumps(hp_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) Find the optimal GAN LR, GAN BatchSize-Epoch, AE LR, AE BatchSize-Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "hp = 'gbe_aeb'\n",
    "gbe_aeb = list(itertools.product(HP['gan_lr'], HP['gan_batch_epoch'], HP['ae_lr'], HP['ae_batch_epoch']))\n",
    "gbe_aeb = [elem for elem in gbe_aeb if not ((elem[3] == (256, 50) and elem[1] == (512, 300)) or (elem[1] == (256, 150) and elem[3] == (512, 100)))]\n",
    "\n",
    "for ae_type in tqdm(AE_TYPES):\n",
    "    hp_scores = dict()\n",
    "    printable_ae_dim = max(hp_vals[ae_type]['ae_dim'].items(), key=lambda x: x[1])[0]\n",
    "    ae_dim = tuple(map(int, printable_ae_dim.split('_')))\n",
    "    embedding_dim = int(max(hp_vals[ae_type]['embedding_dim'].items(), key=lambda x: x[1])[0])\n",
    "    printable_gan_layers = max(hp_vals[ae_type]['gan_layers'].items(), key=lambda x: x[1])[0]\n",
    "    gan_layers = tuple(map(int, printable_gan_layers.split('_')))\n",
    "    d_step, pac = list(map(int,max(hp_vals[ae_type]['dstep_pac'].items(), key=lambda x: x[1])[0].split('_')))\n",
    "    for v1, v2, v3, v4 in tqdm(gbe_aeb):\n",
    "        pv2 = '_'.join(map(str,v2))\n",
    "        pv4 = '_'.join(map(str,v4))\n",
    "        k = '_'.join(map(str,[v1,pv2,v3,pv4]))\n",
    "        mpath = f\"../../models/ae_gan_{ae_type}_ae_dim_{printable_ae_dim}_emb_{embedding_dim}_gla_{gan_layers}_dstep_{d_step}_pac_{pac}_glr_{v1}_gbe_{pv2}_alr_{v3}_aeb_{pv4}.pth\"\n",
    "        if not os.path.exists(mpath):\n",
    "            # Train the AE_GAN\n",
    "            print(f\"Training CTGAN: {ae_type} - ae_dim - {printable_ae_dim} - embed_dim - {embedding_dim} - gan_layers - {printable_gan_layers} - dstep - {d_step} - pac - {pac} - gan_lr - {v1} - gan_batch_epoch - {pv2} - ae_lr - {v3} - ae_batch_epoch - {pv4}\")\n",
    "            ae_gan = CTGANV2(ae_type=ae_type, ae_dim=ae_dim, embedding_dim=embedding_dim,\n",
    "                                generator_dim=gan_layers, discriminator_dim=gan_layers,\n",
    "                                discriminator_steps=d_step, pac=pac, generator_lr=v1, discriminator_lr=v1,\n",
    "                                batch_size=v2[0], epochs=v2[1], autoencoder_lr=v3, ae_batch_size=v4[0], ae_epochs=v4[1])\n",
    "            ae_gan.fit(td['train'], dt=dt, is_transformed=True, target_index=target_idx)\n",
    "            print(\"Training Complete!\")\n",
    "            # save model\n",
    "            ae_gan.save(mpath)\n",
    "        else:\n",
    "            print(f\"Loading CTGAN: {ae_type} - ae_dim - {printable_ae_dim} - embed_dim - {embedding_dim} - gan_layers - {printable_gan_layers} - dstep - {d_step} - pac - {pac} - gan_lr - {v1} - gan_batch_epoch - {pv2} - ae_lr - {v3} - ae_batch_epoch - {pv4}\")\n",
    "            ae_gan = CTGANV2().load(mpath)\n",
    "\n",
    "        best_score = torch.tensor([0.0])\n",
    "        try:\n",
    "            # Sample fake data\n",
    "            fake_data, real_data = sample_fake_loan(dt,td,ae_gan)\n",
    "            \n",
    "            print(\"Benchmarking on MLP100\")\n",
    "            # Train the MLP on fake validation data\n",
    "            for _ in range(3):\n",
    "                test_score = train_model(\n",
    "                                fake_data[0],\n",
    "                                fake_data[1],\n",
    "                                fake_data[2],\n",
    "                                fake_data[3],\n",
    "                                real_data[0],\n",
    "                                real_data[1],\n",
    "                                batch_size=256,\n",
    "                                num_epochs=100,\n",
    "                                model_type=\"classification\",\n",
    "                                verbose=False,\n",
    "                                scorer_type=\"f1_micro\",\n",
    "                            )\n",
    "                if test_score > best_score:\n",
    "                    best_score = test_score\n",
    "            print(\"Benchmark Complete!\")\n",
    "        except:\n",
    "            pass\n",
    "        hp_scores[k] = best_score.item()\n",
    "    \n",
    "    hp_vals[ae_type][hp] = hp_scores\n",
    "    with open(\"loan_opt_hp.json\", 'w') as f:\n",
    "        f.write(json.dumps(hp_vals))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc2516",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
