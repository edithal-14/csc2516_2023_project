{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctgan.synthesizers.ae_gan import CTGANV2, AutoEncoderType\n",
    "from aegan_utils import load_news, get_news_Xy, train_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## news dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_train_df, news_valid_df, news_test_df, news_discrete_columns = load_news(path=\"../dataset/news/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla AE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result section (R2 score on real news validation dataset)\n",
    "\n",
    "- AE dimension\n",
    "    - (256, 128)\n",
    "        - -10.73\n",
    "    - (256, 128, 64)\n",
    "        - -0.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesizer = \"ae_gan_vanilla\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CTGANV2(\n",
    "    ae_type=AutoEncoderType.VANILLA,\n",
    "    ae_dim=(256, 128),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_trans = model.transform(news_train_df, discrete_columns=news_discrete_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data transformer and transformed data to a file\n",
    "# with open(\"../dataset/news/data_transformer.pkl\", \"wb\") as fp:\n",
    "#     pickle.dump(model._transformer, fp)\n",
    "# with open(\"../dataset/news/transformed_data.pkl\", \"wb\") as fp:\n",
    "#     pickle.dump(news_trans, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data transformer and transformed data\n",
    "with open(\"../dataset/news/data_transformer.pkl\", \"rb\") as fp:\n",
    "    dt = pickle.load(fp)\n",
    "with open(\"../dataset/news/transformed_data.pkl\", \"rb\") as fp:\n",
    "    news_trans = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 19.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AE-GAN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.03s/it]\n"
     ]
    }
   ],
   "source": [
    "# model.fit(news_trans, discrete_columns=news_discrete_columns, dt=dt, is_pre_transformed=True, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now = datetime.datetime.now()\n",
    "# current_time = now.strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "# model.save(\n",
    "#     f\"../models/news_{synthesizer}.pkl\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CTGANV2.load(\"../models/news_ae_gan_vanilla.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample fake train and validation data\n",
    "news_fake_df = model.sample(news_train_df.shape[0] + news_valid_df.shape[0])\n",
    "news_fake_X, news_fake_y = get_news_Xy(news_fake_df)\n",
    "news_fake_train_X, news_fake_valid_X, news_fake_train_y, news_fake_valid_y = train_test_split(\n",
    "    news_fake_X, news_fake_y, test_size=news_valid_df.shape[0], random_state=1, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get real validation data\n",
    "news_valid_X, news_valid_y = get_news_Xy(news_valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:00<00:05, 16.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 843025955.3131, Valid Loss: 38948064.0000, Valid score: -0.2274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [00:01<00:03, 18.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Training Loss: 32055445.1717, Valid Loss: 34629324.0000, Valid score: -0.0913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [00:03<00:02, 17.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51, Training Loss: 32075379.0101, Valid Loss: 31084516.0000, Valid score: 0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [00:04<00:01, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76, Training Loss: 32100007.8384, Valid Loss: 32326054.0000, Valid score: -0.0187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 17.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation score: 0.030978227793081126\n",
      "Test score: -0.10538640941271993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Check ML efficacy\n",
    "test_score = train_model(\n",
    "    news_fake_train_X,\n",
    "    news_fake_train_y,\n",
    "    news_fake_valid_X,\n",
    "    news_fake_valid_y,\n",
    "    news_valid_X,\n",
    "    news_valid_y,\n",
    "    input_dim=59,\n",
    "    output_dim=1,\n",
    "    batch_size=256,\n",
    "    num_epochs=100,\n",
    "    model_type=\"regression\",\n",
    "    show_print_training_score=False,\n",
    "    scorer_type=\"r2\",\n",
    "    verbose=False\n",
    ")\n",
    "print(f\"Test score: {test_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vanilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
